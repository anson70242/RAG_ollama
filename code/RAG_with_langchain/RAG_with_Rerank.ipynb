{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.1:8b-instruct-fp16\"\n",
    "EMBED_MODEL = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "RERANK_MODEL = \"BAAI/bge-reranker-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "# Initialize an instance of the Ollama model\n",
    "llm = OllamaLLM(model=MODEL, base_url=f\"http://{os.getenv(\"M416_4090\")}:11434\")\n",
    "\n",
    "# Invoke the model to generate responses\n",
    "response = llm.invoke(\"Who are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging face login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli whoami' is deprecated. Use 'hf auth whoami' instead.\u001b[0m\n",
      "\u001b[1muser: \u001b[0m AnsonLau\n",
      "\u001b[1morgs: \u001b[0m discord-community,siphonobench\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On average, cats spend 2/3 of every day sleeping. That means a nine-year-old cat has been awake for only three years of its life.',\n",
       " 'Unlike dogs, cats do not have a sweet tooth. Scientists believe this is due to a mutation in a key taste receptor.',\n",
       " 'When a cat chases its prey, it keeps its head level. Dogs and humans bob their heads up and down.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We simple split by line here, for advance RAG, will will have different chunking strategy.\n",
    "with open(\"../../Docs/Text/cat-facts.txt\", \"r\") as f:\n",
    "  refs = f.read().splitlines()\n",
    "refs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 0}, page_content='On average, cats spend 2/3 of every day sleeping. That means a nine-year-old cat has been awake for only three years of its life.'),\n",
       " Document(metadata={'id': 1}, page_content='Unlike dogs, cats do not have a sweet tooth. Scientists believe this is due to a mutation in a key taste receptor.'),\n",
       " Document(metadata={'id': 2}, page_content='When a cat chases its prey, it keeps its head level. Dogs and humans bob their heads up and down.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create docs using Document datatype from langchain\n",
    "# Each chunk will have a id and content\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [Document(\n",
    "    page_content=doc, \n",
    "    metadata={\"id\": i}\n",
    ") for i, doc in enumerate(refs)]\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding model\n",
    "model_kwargs = {'trust_remote_code': True}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_model = HuggingFaceCrossEncoder(\n",
    "    model_name=RERANK_MODEL,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "compressor = CrossEncoderReranker(model=reranking_model, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma DB\n",
    "vector_store = Chroma.from_documents(docs, embedding = embeddings_model)\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=base_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are a cat expert.Answer the following question using only the information provided in the given context.You don't need to explain te answer.Context: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"You are a cat expert.\"\n",
    "    \"Answer the following question using only the information provided in the given context.\"\n",
    "    \"You don't need to explain te answer.\"\n",
    "    \"\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm = llm, prompt = prompt)\n",
    "# print(question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_retrieval_chain(retriever=compression_retriever, combine_docs_chain=question_answer_chain)\n",
    "# print(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much of a day do cats spend sleeping on av...</td>\n",
       "      <td>2/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the technical term for a cat's hairball?</td>\n",
       "      <td>Bezoar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do scientists believe caused cats to lose...</td>\n",
       "      <td>a mutation in a key taste receptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the top speed a cat can travel over sh...</td>\n",
       "      <td>31 mph, 49 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the organ in a cat's mouth...</td>\n",
       "      <td>Jacobson’s organ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which wildcat is considered the ancestor of al...</td>\n",
       "      <td>the African Wild Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the group term for cats?</td>\n",
       "      <td>clowder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many different sounds can cats make?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the name of the first cat in space?</td>\n",
       "      <td>Felicette, Astrocat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How many toes does a cat have on its back paws?</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  How much of a day do cats spend sleeping on av...   \n",
       "1   What is the technical term for a cat's hairball?   \n",
       "2  What do scientists believe caused cats to lose...   \n",
       "3  What is the top speed a cat can travel over sh...   \n",
       "4  What is the name of the organ in a cat's mouth...   \n",
       "5  Which wildcat is considered the ancestor of al...   \n",
       "6                   What is the group term for cats?   \n",
       "7           How many different sounds can cats make?   \n",
       "8        What is the name of the first cat in space?   \n",
       "9    How many toes does a cat have on its back paws?   \n",
       "\n",
       "                              answers  \n",
       "0                                 2/3  \n",
       "1                              Bezoar  \n",
       "2  a mutation in a key taste receptor  \n",
       "3                       31 mph, 49 km  \n",
       "4                    Jacobson’s organ  \n",
       "5                the African Wild Cat  \n",
       "6                             clowder  \n",
       "7                                 100  \n",
       "8                 Felicette, Astrocat  \n",
       "9                                four  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../Docs/test.csv\", sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = data['queries']\n",
    "answers = data['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How much of a day do cats spend sleeping on average?\n",
      "Response: 2/3 of the day, which is 16 to 18 hours.\n",
      "\n",
      "Query: What is the technical term for a cat's hairball?\n",
      "Response: Bezoar.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What do scientists believe caused cats to lose their sweet tooth?\n",
      "Response: A mutation in a key taste receptor.\n",
      "\n",
      "Query: What is the top speed a cat can travel over short distances?\n",
      "Response: 31 mph (49 km)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the name of the organ in a cat's mouth that helps it smell?\n",
      "Response: The Jacobson’s organ.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which wildcat is considered the ancestor of all domestic cats?\n",
      "Response: The African Wild Cat.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the group term for cats?\n",
      "Response: A \"clowder.\"\n",
      "\n",
      "Query: How many different sounds can cats make?\n",
      "Response: About 100 different sounds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the name of the first cat in space?\n",
      "Response: Felicette (a.k.a. “Astrocat”)\n",
      "\n",
      "Query: How many toes does a cat have on its back paws?\n",
      "Response: 4\n",
      "\n",
      "Correct numbers: 7\n",
      "The following queries were answered incorrectly:\n",
      "What is the top speed a cat can travel over short distances?\n",
      "What is the name of the first cat in space?\n",
      "How many toes does a cat have on its back paws?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m416-4090/anaconda3/envs/RAG/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "counts = 0\n",
    "wrong_queries = []\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    response = chain.invoke({\"input\": query})\n",
    "    print(f\"Query: {query}\\nResponse: {response['answer']}\\n\")\n",
    "    \n",
    "    # The following lines perform evaluations.\n",
    "    # if the answer shows up in your response, the response is considered correct.\n",
    "    is_correct = False\n",
    "    if isinstance(answers[i], list):\n",
    "        for answer in answers[i]:\n",
    "            if answer.lower() in response['answer'].lower():\n",
    "                counts += 1\n",
    "                is_correct = True\n",
    "                break\n",
    "    else:\n",
    "        if answers[i].lower() in response['answer'].lower():\n",
    "            counts += 1\n",
    "            is_correct = True\n",
    "    \n",
    "    if not is_correct:\n",
    "        wrong_queries.append(query)\n",
    "\n",
    "# Improve to let the LLM correctly answer the ten questions.\n",
    "print(f\"Correct numbers: {counts}\")\n",
    "if wrong_queries:\n",
    "    print(\"The following queries were answered incorrectly:\")\n",
    "    for q in wrong_queries:\n",
    "        print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
